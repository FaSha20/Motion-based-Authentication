# احراز هویت مبتنی بر حرکت  
## آشنایی با سیستم عامل اندروید و استفاده از سنسورهای تلفن همراه
###شرح پروژه: 
در این پروژه قصد داریم با استفاده از سنسورهای شتاب سنج و ژیروسکوپ در تلفن همراه هوشمند، با سیستم عامل اندروید، یک سیستم احراز هویت مبتنی بر حرکت تلفن همراه هوشمند بسازیم. این سیستم شامل دو مرحله اصلی است: مرحله ذخیره سازی و مرحله احراز هویت. درمرحله ذخیره سازی، یک الگوی حرکتی را از کاربر دریافت و ذخیره کرده و در مرحله احراز هویت حرکت دستگاه را با الگوی ذخیره شده مقایسه میکند و تطابق یا عدم تطابق را بررسی میکند. 

### مفروضات: 
- دستگاه حرکت اریب ندارد و در هر لحظه تنها در یکی از دو جهت x و y در حال حرکت است.
- سه بار دریافت متوالی مقدار صفر در هر جهت، به معنای پایان حرکت در آن جهت است و دیگر حرکت در آن جهت ادامه نخواهد داشت.
- بین حرکات path باید به اندازه threshhold مکت وجود داشته باشد و به سرعت تغییر جهت نداشته باشیم. 
- حرکات باید با شتاب انجام شوند و اگر با سرعت ثابت حرکت داده شود، موفقیت آمیز نخواهد بود.
- هنگام چرخش حول محور z تلاش شود که لرزش و تغییر در مقادیر x و y نداشته باشیم. 

<br/><br/>
### طراحی مفهومی و ساختار برنامه اندرویدی 
در این بخش به بررسی و شرح ساختار برنامه اندرویدی میپردازیم: 
<br/><br/>
![image (16)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/a95fbe33-3c5b-4cd9-b3f5-baf84e0ad77d)
<br/><br/>
ساختار برنامه اندرویدی در نمای دیرکتوریها مشخص است. برنامه ما در محیط اندروید استودیو و به زبان جاوا نوشته شده است و از تعدادی پوشه متشکل شده است. پوشه اول پوشه manifest شامل فایل AndroidManifest.xml است (که در تصویر بالا نیز محتوای آن نمایش داده شده است.) که در آن مشخص میکنیم که از چه فیچرهایی داریم استفاده میکنیم. مثلا در خط 5 و 6 میبینیم که نوشته شده از سنسورهای شتاب سنج و ژیروسکوپ داریم استفاده میکنیم. همچنین یک پوشه جاوا داریم که شامل سه فایل MainActivity (که همان main برنامه ماست) و MotionCapture و Path است. 
<br/><br/>
در بخش res>layout یک فایل activity_main.xml هست که در ادامه به شرح آن خواهیم پرداخت.
<br/><br/>
![image (17)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/636e4cf0-ed7a-4b98-a149-b94d925e7b4e)
<br/><br/>
تصویر بالا تصویری از فایل activity_main.xml است که به نوعی کدهای مربوط به UI کار در این فایل قرار دارد. اینکه چند دکمه یا button داشته باشد، چند text view داشته باشد و هر آن المانی که روی صفحه نمایش داده میشود، با جزئیاتی از قبیل اندازه و رنگ و... را در این فایل مشخص میکنیم. همچنین قابلیت split دارد که میتوان پیشنمایش UI را در صفحه هنگام کار دید و تغییرات را اعمال کرد. همچنین میشود مستقیم روی این UI تغییرات را اعمال کرد و نیازی به صرف کد زدن نیز نیست. 
<br/><br/>
![image (18)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/d7a10214-be0b-4214-a167-a4cbb992e4af)
<br/><br/>
![image (19)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/1c9d7477-91ae-453b-b3ed-20b9a9c45c08)
<br/><br/>
عکس بالا تصویری از فایل MainActivity است. MainActivity در واقغ همان main کار است که در آن، تک تک المانهایی که در صفحه ساخته شده اند، با آن ID که مشخص کرده ایم، با تابع findViewByID پیدا میکنیم و در باتنی به همان اسم میریزیم. سپس برای هرکدام یک On click listener ست میکنیم. به این معنا که وقتی روی این دکمه کلیک شد، این listener را فعال کن. به طور مثال برای بخش اول start capture button یک set on click listener زده ایم (عکس دو) که وقتی روی آن کلیک شود، تمام text view ها را پاک میکند و capture را آغاز میکند. آبجکت motion capture هم در حقیقت همان object اصلی است که دارد کار میکند. main این آبجکت را صدا میزند و رویش عملیات ها را انجام میدهد. 
<br/><br/>
![image (20)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/e1d7c416-4e05-4c4e-b905-e4724db40bf1)
<br/><br/>
این عکس نیز مثال دیگری مربوط به دکمه check pattern است که initial path ای که ساخته را با path ای که گرفته به عنوان ورودی میگیرد و باهم چک میکند که آیا مچ هستند یا خیر. اگر valid باشد، تکست را به تکست valid ست میکند و در غیر این صورت، تکست را fail ست میکند.
<br/><br/>
![image (21)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/81fecda4-8735-4911-9be2-949c4c703808)
<br/><br/>
این بخش مربوط به کلاس Motion Capture است که اصل کار است. ابتدا پارامتر های اولیه را تعریف و ست میکنیم. یک constructor دارد که در آن، ابتدا یک sensor manager میسازد و به سیستم اعلام میکند که من میخواهم از سنسورهای تو استفاده کنم! خروجی این درخواست به سیستم در sensorManager میریزد. اگر این مقدار null نبود، یعنی دسترسی sensormanager داده شده است. آن وقت به سیستم اعلام میشود که من میخواهم از سنسور شتاب سنج و ژیروسکوپ تو استفاده کنم! پس دو سنسور از این تایپ برای ما میسازد. یک شتاب سنج و یک ژیروسکوپ. 
<br/><br/>
سپس مقادیر اولیه ای ست میشود. caturing را false میکنیم به معنای آنکه درحال دریافت حرکت نیستیم. پارامتر move (که به معنای آن است که نویت حرکت چه محوری است؟ محور x یا محور y، و یا آیا اصلا نوبت حرکتی است؟ 0 بودن این پارامتر به معنای این است که نویت حرکت در هیچ محوری نیست و چیزی دریافت نشده است.) motion pattern builder نیز چیزی است که pattern حرکت را در آن ذخیره میکنیم و در اینجا new میشود. 
<br/><br/>
![image (22)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/9af6094a-60eb-4c63-a8cf-03d32598b064)
<br/><br/>
در start capture، ما میخواهیم پترن اولیه را از کاربر بگیریم. مقادیر اولیه برای آغاز گرفتن یک path جدید را ست و ریست میکنیم و یک path جدید را new میکند. خط 54 استرینگ سر لیست پترنی که قرار است بگیرد و در motion pattern builder ذخیره کند را ست میکند. 
در خط 57 و 58، نرخ یا rate نمونه برداری را برای این دو سنسور مشخص میکند. مثلا برای شتاب سنج، sensor manager را SENSOR_DELAY_NORMAL ست میکند. برای برنامه ما ریت نرمال کفایت میکند. برای هردو در این بخش نرخ نمونه برداری را تعیین میکنیم. 
<br/><br/>
![image (23)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/eeb96a2c-3300-4b6b-9ffe-e327670275bf)
<br/><br/>
در بخش stop capture، مقدار فلگ capturing را false میکند و listener را نیز unregister میکند و مسیری که تا کنون capture کرده را بر میگرداند. دو تابع پایین هم دو گتر ساده هستند که یکی path و دیگری motion pattern را برمیگرداند. تفاوت path و motion pattern در این است که motion pattern صرفا دیتایی که از سنسورها خوانده شده است را برمیگرداند. مثلا میگوید موقعیت ابتدا در فلان مختصات بوده و دو ثانیه بعد در فلان مختصات قرار گرفته است. یعنی لیست کامل تمام نمونه برداری هایی که با نرخ تعیین شده انجام داده است را برمیگرداند. path اما همان خروجی ای است که ما میخواهیم. یعنی اینکه مثلا حرکت در نهایت -بر اساس دیتاهایی که تحلیل کرده- دو گام به چپ بوده است. 
<br/><br/>
![image (24)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/3aed4648-993c-4e40-9a0a-b9718f3be8c4)
<br/><br/>
متد onSensorChanged اولین متدی است که باید override شود و از motion capure listener آن را extend میکنیم. این متد میگوید که اگر سنسور عوض شد، چکار کن! و event -اتفاقی که رخ داده است- را به عنوان ورودی میگیرد. اگر این event از نوع دیتای شتاب سنج است، مقادیر و valueهای 0 و 1 این event را در x و y (لوکیشن) ذخیره کن. اگر تایپ event از نوع ژیروسکوپ است، value[2] را بگیر و ذخیره کن. چرا که ما تنها چرخش حول محور z مدنظرمان است. در حقیقت تمام این داده های x و y و z از جنس شتاب هستند. شتاب در راستای x , y و شتاب چرخشی در راستای z. و ما باید این شتاب را تبدیل به لوکیشن و مسافت کنیم. به این منظور ابتدا یک بار انتگرال میگیریم که متغیر سرعت بشود، و سپس مجددا انتگرال میگیریم که به جا به جایی برسیم. اما ما در این پروژه تنها برای w این انتگرال گیری را اعمال کرده ایم و برای x و y اعمال نکرده ایم و این مقادیر شتاب را عملا همان x و y در نظر گرفته ایم. زیرا هرچه این حرکت دستگاه در یک محور طولانی تر شود، معمولا شتاب بیشتری هم میگیرد. فلذا چندان لزومی ندارد که حتما این تغییر اعمال شود و جواب میدهد. 
<br/><br/>
برای محاسبات ژیروسکوپ و تبدیل شتاب زاویه ای به سرعت زاویه ای، یک delta t با زدن تایم استمپ میسازد، در شتاب ضرب میکند و به درجه تبدیل میکند که z را بدهد. در انتها هم تایم استمپ را برای استفاده دفعه بعد، آپدیت میکند. همچنین x و y و z ای که گرفته است را به pattern builder اضافه میکند. 
<br/><br/>
![image (25)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/413cfd64-0426-4ab7-bbc7-1097704fd1e7)
<br/><br/>
در این مرحله ما دیتای سنسورها را گرفته و ذخیره کرده ایم. میخواهیم مسیری که دستگاه رفته است را بر اساس این دیتا پیش بینی کنیم. اگر نویت کسی تا حالا نبوده است و تازه فرآیند را آغاز کرده ایم، زمانی که x بالاتر از 1 شد (یعنی دستگاه یک حرکت واقعی را آغاز کرده و سنسور آن را دیتکت کرده است) یعنی در راستای x حرکتی دارد مشاهده میشود. وقتی abs(x) بزرگتر از 1 شد، start x را ست میکنیم. x دارد حرکت میکند پس محل اولیه اش را ست میکنیم، نویت را به x میدهیم و تعداد zeroها , nonZero ها را نیز صفر کن. برای y هم به همین صورت. 
<br/><br/>
![image (26)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/ffb921c1-d172-4fbc-b564-c051a8f6c1a9)
<br/><br/>
هربار که این سنسور change کند، این تابع کال میشود. فرض میکنیم با نرخ 1 ثانیه سمپلینگ، در ثانیه اول نویت برای هیچ کس نبوده و به x داده ایم. در ثانیه دوم که این تابع صدا زده شود، نوبت برای x است. همچنین فرض گرفته ایم که دو محور x و y باهم حرکت نمیکنند. یعنی حرکت اریب نداریم و تنها در راستای دو محور حرکت میکنیم. پس وقتی نویت x بوده، با محل فعلی x و نقطه شروع x -که ذخیره کرده ایم-، جابه جایی میان این دو نقطه را بدست می آوریم. اگر از maxDistanceX بیشتر شده، آپدیت کن. همچنین چون این احتمال وجود دارد که مقداری که سنسور ثبت کرده، نویز بوده باشد و نه حرکت واقعی، تعداد صفرهایی که پس از یک رکورد غیر صفر دیده میشود را نیز نگه میداریم که اگر از یک میزان threshhold بیشتر بود، نویز تشخیص داده شده و ریست شود. همچنین تعداد رکوردهای غیرصفر را نیز نگه میداریم. اگر تعداد صفرها از threshhold بیشتر بود (که ما به صورت تجربی به عدد 3 رسیده ایم) دیگر نویت آن جهت نیست پس نویت در هر صورت گرفته میشود (Move=0). چه حرکت تمام شده باشد و چه نویز باشد. اما تنها در صورتی این مسیری که تا حالا طی شده را به path اضافه میکنیم که تعداد nonZero های میان دو صفر دیتکت شده از یک حدی بیشتر باشد. اگر کمتر باشد یعنی نویز بوده و نیاز نیست به عنوان یک آیتم path به آن اضافه شود. یک آیتم path شامل جهت حرکت، درجه و مسافتی که طی شده است. مسافت را پیشتر از کم کردن x فعلی و x start بدست آوریم، جهت را از نقطه شروع و زاویه دستگاه حساب میکند و زاویه هم، زاویه گرد شده مقداری است که از ژیروسکوپ دریافت کرده ایم. چون در این پروژه تنها 0 و 90 و 180 , -90 برای ما اهمیت دارند و نیاز است داده های میان اینها، به سمت یکی گرد شوند. در ادامه توابع مربوط به درجه و جهت را توضیح خواهیم داد. 
<br/><br/>
![image (27)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/ab5dceef-300b-4eba-9aab-b9dc0160b2ed)
<br/><br/>
![image (28)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/59d40561-4b21-46ad-8bee-f395d6107787)
<br/><br/>
تابع RoundingAngle نکته ای که وجود دارد این است که برداشتهایش برعکس جهات مثلثاتی است. یعنی اگر 90 درجه ساعتگرد چرخش داشته باشیم، سنسور -90 ثبت میکند. به همین علت است که -z را برای ذخیره شدن پاس دادیم، نه z را. 
<br/><br/>
تابع calculateHorizontalDirection با توجه به زاویه حرکت و جهت اولیه، جهت را به درستی تجسم و لحاظ میکند و جهت صحیح را برای اضافه شدن به path محاسبه و ثبت میکند. عینا همین کارها را برای y هم انجام میدهیم. 
<br/><br/>
![image (30)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/15ecc1d0-b4a4-4c4e-b352-2f366eb86430)
<br/><br/>
ما در این پروژه از یک آبجکت path داریم که همانطور که در بخش قبل دیدیم، آیتمها را پراسس کرده و اضافه میکنیم و لیستی از این path itemها را نگه میدارد. یک متد addItem و یک متد isMatch دارد. 
<br/><br/>
![image (31)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/d4be85ea-f8d2-4946-a80d-40ffc2259b6c)پ
<br/><br/>
متد isMatch یک path و یک threshhold که در حقیقت دقت آن را مشخص میکند، میگیرد و مقایسه میکند که آیا path دریافتی، با path ای که از پیش در سیستم ثبت شده مطابقت دارد یا خیر. دو پارامتر angle و direction را به صورت مستقیم به ازای تک تک path item ها چک میکند و اگر مغایرتی وجود داشت، رد میکند. و نیز باتوجه به threshhold ای که به آن داده ایم، distance را تا آن میزان خطا تحمل میکند. این خطا هم به نسبت بالاست. ما در این پروژه میزان threshhold را 3 داده ایم. که این یعنی 4 را با 7 مساوی در نظر میگیرد. یک متد toString نیز داریم که صرفا داده های path را به صورت یک استرینگ منظم تنظیم کرده و برمیگرداند. 
<br/><br/>
![image (32)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/d6bdd74a-2720-4f5b-bad5-fae12b70c2c2)
<br/><br/>

### تست:
در بخش device manager محیط android studio میتوان دستگاه اندروید (موبایل، تبلت و..) را به آن شناسایی کرد و محیط برنامه روی صفحه نمایش داده میشود. تغییرات وحرکات را حتی میتوان در همین محیط و با ابزارهای اندروید استودیو شبیه سازی کرد. اما به صورت فیزیکی نیز قابل اتصال و تست است و ما در اینجا با کابل گوشی اندروید را به سیستم متصل کرده ایم و آنچه در ادامه در تصاویر مشاهده میشود، صفحه تلفن همراه است. برای استفاده از این برنامه، start capture را میزنیم و پترنی را به آن میدهیم. 
<br/><br/>
![image (33)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/4e85daf7-854d-4016-aa18-4e92309845f7)
<br/><br/>
تست: بالا/ راست/پایین/چپ
<br/><br/>
سپس stop capture را میزنیم و در این صفحه دو گزینه دیگر داریم: show pattern و show distance. گزینه show pattern تمام آن x , y و zهای خامی که دریافت کرده را به ترتیت نمایش میدهد. show distance آن path ای که فهم کرده را نمایش میدهد. 

![image (34)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/97b2c325-5670-45a6-b171-374980abced0)
<br/><br/>
![image (35)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/15b18b5c-af9e-48ac-bef6-32afab97ef50)
<br/><br/>
پس از اینکه stop capture را زدیم، دکمه start authentication را میزنیم که فرآیند مچ کردن پترن دریافتی با پترن اصلی را آغاز میکند. این دکمه تابع isMatch را روی پترن دریافتی صدا میزند و تایید یا رد میکند. 
<br/><br/>
![image (36)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/e9990815-427a-453a-8896-07b3f5c36a8f)
<br/><br/>
![image (37)](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/d8307e75-0772-4495-aa42-028616bed288)
<br/><br/>

### تصاویر پرفتو
<br/><br/>
![photo_2024-05-24_21-51-03](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/da16e938-b8b5-45d5-89d9-67820aeccd65)
<br/><br/>
تصویر تب سنسورها را مشاهده میکنیم. gyrocal مربوط به کالیبره شدن ژیروسکوپ توسط گوشی است و POSIX timer یک کلاک نرم افزاری است که توسط سیستم عامل اندروید استفاده میشود که تسکها را هندل کند. 
<br/><br/>
![photo_2024-05-24_21-54-19](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/2cccd560-4e06-484f-9c7a-deafc570fffd)
<br/><br/>
![photo_2024-05-24_21-54-24](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/b853debd-79dc-458e-afd3-28ed32ed8f1d)
<br/><br/>
![photo_2024-05-24_21-54-30](https://github.com/FaSha20/Motion-based-Authentication/assets/114980788/fb2c1b0c-e260-476a-9484-7ae22aed7a22)
<br/><br/>

### پاسخ به سوالات: 

